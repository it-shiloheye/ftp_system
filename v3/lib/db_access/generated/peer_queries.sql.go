// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.26.0
// source: peer_queries.sql

package db_access

import (
	"context"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

const connectClient = `-- name: ConnectClient :many
SELECT id, peer_id, ip_address, peer_role, peer_name, creation_time, pem, peer_config FROM peers_table
WHERE
    peer_id = $1
LIMIT 1
`

// ConnectClient
//
//	SELECT id, peer_id, ip_address, peer_role, peer_name, creation_time, pem, peer_config FROM peers_table
//	WHERE
//	    peer_id = $1
//	LIMIT 1
func (q *Queries) ConnectClient(ctx context.Context, db DBTX, peerID pgtype.UUID) ([]*PeersTable, error) {
	rows, err := db.Query(ctx, connectClient, peerID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []*PeersTable{}
	for rows.Next() {
		var i PeersTable
		if err := rows.Scan(
			&i.ID,
			&i.PeerID,
			&i.IpAddress,
			&i.PeerRole,
			&i.PeerName,
			&i.CreationTime,
			&i.Pem,
			&i.PeerConfig,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const createClient = `-- name: CreateClient :one
INSERT INTO peers_table(ip_address,peer_name,pem)
VALUES ($1,$2,$3)
RETURNING 
    peer_id, peer_role
`

type CreateClientParams struct {
	IpAddress string  `json:"ip_address"`
	PeerName  *string `json:"peer_name"`
	Pem       []byte  `json:"pem"`
}

type CreateClientRow struct {
	PeerID   pgtype.UUID      `json:"peer_id"`
	PeerRole NullPeerRoleType `json:"peer_role"`
}

// CreateClient
//
//	INSERT INTO peers_table(ip_address,peer_name,pem)
//	VALUES ($1,$2,$3)
//	RETURNING
//	    peer_id, peer_role
func (q *Queries) CreateClient(ctx context.Context, db DBTX, arg *CreateClientParams) (*CreateClientRow, error) {
	row := db.QueryRow(ctx, createClient, arg.IpAddress, arg.PeerName, arg.Pem)
	var i CreateClientRow
	err := row.Scan(&i.PeerID, &i.PeerRole)
	return &i, err
}

const dBCurrentStorageSize = `-- name: DBCurrentStorageSize :one
SELECT SUM(file_size) FROM file_metadata 
JOIN file_data ON file_metadata.file_data_id = file_data.id
WHERE file_metadata.file_state = 'current'
`

// DBCurrentStorageSize
//
//	SELECT SUM(file_size) FROM file_metadata
//	JOIN file_data ON file_metadata.file_data_id = file_data.id
//	WHERE file_metadata.file_state = 'current'
func (q *Queries) DBCurrentStorageSize(ctx context.Context, db DBTX) (int64, error) {
	row := db.QueryRow(ctx, dBCurrentStorageSize)
	var sum int64
	err := row.Scan(&sum)
	return sum, err
}

const dBTotalStorageSize = `-- name: DBTotalStorageSize :one
SELECT SUM(file_size) FROM file_data
`

// DBTotalStorageSize
//
//	SELECT SUM(file_size) FROM file_data
func (q *Queries) DBTotalStorageSize(ctx context.Context, db DBTX) (int64, error) {
	row := db.QueryRow(ctx, dBTotalStorageSize)
	var sum int64
	err := row.Scan(&sum)
	return sum, err
}

const getFilesList = `-- name: GetFilesList :many
SELECT DISTINCT file_path, dir_id,  file_type, file_state, file_data.id, 
file_metadata.id as file_metadata_id,file_mode, 
file_metadata.mod_time,  file_data.file_hash, file_data.file_size FROM file_metadata
JOIN file_data ON file_metadata.file_data_id = file_data.id
WHERE file_state = 'current'
ORDER BY file_metadata.mod_time DESC
`

type GetFilesListRow struct {
	FilePath       string             `json:"file_path"`
	DirID          *int32             `json:"dir_id"`
	FileType       string             `json:"file_type"`
	FileState      string             `json:"file_state"`
	ID             int32              `json:"id"`
	FileMetadataID int32              `json:"file_metadata_id"`
	FileMode       int32              `json:"file_mode"`
	ModTime        pgtype.Timestamptz `json:"mod_time"`
	FileHash       *string            `json:"file_hash"`
	FileSize       int32              `json:"file_size"`
}

// GetFilesList
//
//	SELECT DISTINCT file_path, dir_id,  file_type, file_state, file_data.id,
//	file_metadata.id as file_metadata_id,file_mode,
//	file_metadata.mod_time,  file_data.file_hash, file_data.file_size FROM file_metadata
//	JOIN file_data ON file_metadata.file_data_id = file_data.id
//	WHERE file_state = 'current'
//	ORDER BY file_metadata.mod_time DESC
func (q *Queries) GetFilesList(ctx context.Context, db DBTX) ([]*GetFilesListRow, error) {
	rows, err := db.Query(ctx, getFilesList)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []*GetFilesListRow{}
	for rows.Next() {
		var i GetFilesListRow
		if err := rows.Scan(
			&i.FilePath,
			&i.DirID,
			&i.FileType,
			&i.FileState,
			&i.ID,
			&i.FileMetadataID,
			&i.FileMode,
			&i.ModTime,
			&i.FileHash,
			&i.FileSize,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPEMs = `-- name: GetPEMs :many
SELECT pem FROM peers_table
`

// GetPEMs
//
//	SELECT pem FROM peers_table
func (q *Queries) GetPEMs(ctx context.Context, db DBTX) ([][]byte, error) {
	rows, err := db.Query(ctx, getPEMs)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := [][]byte{}
	for rows.Next() {
		var pem []byte
		if err := rows.Scan(&pem); err != nil {
			return nil, err
		}
		items = append(items, pem)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const updateFileTracker = `-- name: UpdateFileTracker :exec
INSERT INTO file_tracker (
    peer_id,
    file_meta_id,
    current_hash_id,
    file_state
) VALUES ($1, $2, $3, $4)
`

type UpdateFileTrackerParams struct {
	PeerID        uuid.UUID `json:"peer_id"`
	FileMetaID    int32     `json:"file_meta_id"`
	CurrentHashID int32     `json:"current_hash_id"`
	FileState     string    `json:"file_state"`
}

// UpdateFileTracker
//
//	INSERT INTO file_tracker (
//	    peer_id,
//	    file_meta_id,
//	    current_hash_id,
//	    file_state
//	) VALUES ($1, $2, $3, $4)
func (q *Queries) UpdateFileTracker(ctx context.Context, db DBTX, arg *UpdateFileTrackerParams) error {
	_, err := db.Exec(ctx, updateFileTracker,
		arg.PeerID,
		arg.FileMetaID,
		arg.CurrentHashID,
		arg.FileState,
	)
	return err
}
